import numpy as np
import pandas as pd
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix
from sklearn.metrics import roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import sys
import os

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from scripts.data_preprocessing import preprocess_pipeline


def train_svm(X_train, y_train, random_state=42):
    # Initialize SVM with optimal parameters from comparison
    svm_model = SVC(
        kernel='rbf',
        C=1.0,
        gamma='scale',
        class_weight='balanced',
        random_state=random_state,
        probability=True  # Enable probability estimates
    )
    
    # Train the model
    svm_model.fit(X_train, y_train)
    
    return svm_model


def evaluate_model(model, X_test, y_test):
    # Generate predictions
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of positive class
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    # Create metrics summary
    metrics = {
        'accuracy': accuracy,
        'f1_score': f1,
        'roc_auc': roc_auc
    }
    
    # Print results
    print("SVM Model Performance Metrics:")
    print("=" * 40)
    print(f"Accuracy:  {accuracy:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    print(f"ROC AUC:   {roc_auc:.4f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant']))
    
    return metrics, y_pred, y_pred_proba


def extract_feature_coefficients(model, feature_names):
    # Get support vector information
    n_support = model.n_support_
    support_vectors = model.support_vectors_
    
    # Create summary of support vectors
    support_info = pd.DataFrame({
        'class': ['Benign', 'Malignant'],
        'n_support_vectors': n_support,
        'percentage': (n_support / len(model.support_vectors_)) * 100
    })
    
    return support_info


def save_predictions(X_test, y_test, y_pred, y_pred_proba, output_dir="outputs"):
    # Create predictions dataframe
    predictions_df = pd.DataFrame({
        'true_label': y_test,
        'predicted_label': y_pred,
        'predicted_probability': y_pred_proba,
        'correct_prediction': (y_test == y_pred).astype(int)
    })
    
    # Add feature values 
    feature_cols = X_test.columns[:5]
    for col in feature_cols:
        predictions_df[f'feature_{col}'] = X_test[col].values
    
    # Save to CSV
    os.makedirs(output_dir, exist_ok=True)
    predictions_df.to_csv(f"{output_dir}/svm_predictions.csv", index=False)
    
    print(f"\nPredictions saved to {output_dir}/svm_predictions.csv")
    return predictions_df


def create_visualizations(model, X_test, y_test, y_pred_proba, support_info, output_dir="outputs"):
    # Set up the plotting style
    plt.style.use('default')
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('SVM Model Performance', fontsize=16)
    
    # Support Vectors Information
    axes[0, 0].bar(support_info['class'], support_info['n_support_vectors'], color=['lightblue', 'lightcoral'])
    axes[0, 0].set_xlabel('Class')
    axes[0, 0].set_ylabel('Number of Support Vectors')
    axes[0, 0].set_title('Support Vectors by Class')
    for i, v in enumerate(support_info['n_support_vectors']):
        axes[0, 0].text(i, v + 1, str(v), ha='center', va='bottom')
    
    # ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    axes[0, 1].plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.3f})')
    axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')
    axes[0, 1].set_xlabel('False Positive Rate')
    axes[0, 1].set_ylabel('True Positive Rate')
    axes[0, 1].set_title('ROC Curve')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # Precision-Recall Curve
    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
    axes[1, 0].plot(recall, precision)
    axes[1, 0].set_xlabel('Recall')
    axes[1, 0].set_ylabel('Precision')
    axes[1, 0].set_title('Precision-Recall Curve')
    axes[1, 0].grid(True, alpha=0.3)
    
    # Confusion Matrix
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Benign', 'Malignant'],
                yticklabels=['Benign', 'Malignant'],
                ax=axes[1, 1])
    axes[1, 1].set_title('Confusion Matrix')
    axes[1, 1].set_xlabel('Predicted')
    axes[1, 1].set_ylabel('Actual')
    
    plt.tight_layout()
    
    # Save the plot
    os.makedirs(output_dir, exist_ok=True)
    plt.savefig(f"{output_dir}/svm_model_performance.png", dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nVisualization saved to {output_dir}/svm_model_performance.png")


def run_svm_pipeline(file_path):
    print("Starting SVM Machine Learning Pipeline...")
    print("=" * 50)
    
    # Load and preprocess data
    print("1. Loading and preprocessing data...")
    X_train, X_test, y_train, y_test = preprocess_pipeline(file_path)
    
    # Select the same features as in comparison
    selected_features = [
        'concave points_mean','area_worst','fractal_dimension_worst','smoothness_worst','symmetry_worst',
        'fractal_dimension_mean','smoothness_mean','compactness_se','fractal_dimension_se','concave points_se',
        'symmetry_se','perimeter_se','concavity_se','symmetry_mean','smoothness_se','texture_se','texture_mean'
    ]
    
    # Filter to selected features
    X_train_selected = X_train[selected_features]
    X_test_selected = X_test[selected_features]
    
    print(f"   - Training samples: {len(X_train_selected)}")
    print(f"   - Test samples: {len(X_test_selected)}")
    print(f"   - Features used: {len(selected_features)}")
    
    # Train SVM model
    print("\n2. Training SVM model...")
    model = train_svm(X_train_selected, y_train)
    print("   - Model training completed")
    print(f"   - Support vectors used: {len(model.support_vectors_)}")
    
    # Evaluate model
    print("\n3. Evaluating model performance...")
    metrics, y_pred, y_pred_proba = evaluate_model(model, X_test_selected, y_test)
    
    # Extract support vector information
    print("\n4. Extracting support vector information...")
    support_info = extract_feature_coefficients(model, selected_features)
    print("Support Vector Summary:")
    print(support_info)
    
    # Save results
    print("\n5. Saving results...")
    
    # Save predictions
    predictions_df = save_predictions(X_test_selected, y_test, y_pred, y_pred_proba)
    
    # Save support vector info
    support_info.to_csv("outputs/svm_support_vectors.csv", index=False)
    print("Support vector info saved to outputs/svm_support_vectors.csv")
    
    # Save model metrics
    metrics_df = pd.DataFrame([metrics])
    metrics_df.to_csv("outputs/svm_model_metrics.csv", index=False)
    print("Model metrics saved to outputs/svm_model_metrics.csv")
    
    # Save trained model
    joblib.dump(model, "outputs/trained_svm_model.pkl")
    print("Trained SVM model saved to outputs/trained_svm_model.pkl")
    
    # Create visualizations
    print("\n6. Creating visualizations...")
    create_visualizations(model, X_test_selected, y_test, y_pred_proba, support_info)
    
    print("\n" + "=" * 50)
    print("SVM Machine Learning Pipeline Complete!")
    print(f"Final Performance: {metrics['accuracy']:.1%} accuracy, {metrics['roc_auc']:.3f} ROC AUC")
    
    return model, metrics, support_info, predictions_df


# Run the pipeline
if __name__ == "__main__":
    model, metrics, support_info, predictions = run_svm_pipeline("data/breast-cancer.csv")